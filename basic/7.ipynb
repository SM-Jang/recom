{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3) (25000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH = 'C:/RecoSys/Data/'\n",
    "r_cols = ['user_id','movie_id','rating','timestamp']\n",
    "ratings = pd.read_csv(PATH+'u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
    "\n",
    "ratings_train, ratings_test = train_test_split(ratings, train_size=0.75, shuffle=True)\n",
    "print(ratings_train.shape, ratings_test.shape)\n",
    "\n",
    "\n",
    "# Defining RMSE measure\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5616667691468702"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# Dummy recommender 0\n",
    "def recommender0(recomm_list):\n",
    "    recommendations = []\n",
    "    for pair in recomm_list:\n",
    "        recommendations.append(random.random()*4+1)\n",
    "    return np.array(recommendations)\n",
    "\n",
    "# Dummy recommender 1\n",
    "def recommender1(recomm_list):\n",
    "    recommendations = []\n",
    "    for pair in recomm_list:\n",
    "        recommendations.append(random.random()*4+1)\n",
    "    return np.array(recommendations)\n",
    "\n",
    "# 정확도(RMSE)를 계산하는 함수 \n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "# Hybrid 결과 얻기\n",
    "weight = [0.8, 0.2]\n",
    "recomm_list = np.array(ratings_test)\n",
    "predictions0 = recommender0(recomm_list)\n",
    "predictions1 = recommender1(recomm_list)\n",
    "predictions = predictions0*weight[0] + predictions1*weight[1]\n",
    "RMSE2(recomm_list[:,2], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9678 ; Test RMSE = 0.9804\n",
      "Iteration: 20 ; Train RMSE = 0.9434 ; Test RMSE = 0.9606\n",
      "Iteration: 30 ; Train RMSE = 0.9326 ; Test RMSE = 0.9525\n",
      "Iteration: 40 ; Train RMSE = 0.9265 ; Test RMSE = 0.9483\n",
      "Iteration: 50 ; Train RMSE = 0.9225 ; Test RMSE = 0.9458\n",
      "Iteration: 60 ; Train RMSE = 0.9197 ; Test RMSE = 0.9441\n",
      "Iteration: 70 ; Train RMSE = 0.9176 ; Test RMSE = 0.9430\n",
      "Iteration: 80 ; Train RMSE = 0.9158 ; Test RMSE = 0.9422\n",
      "Iteration: 90 ; Train RMSE = 0.9141 ; Test RMSE = 0.9416\n",
      "Iteration: 100 ; Train RMSE = 0.9123 ; Test RMSE = 0.9409\n",
      "Iteration: 110 ; Train RMSE = 0.9100 ; Test RMSE = 0.9402\n",
      "Iteration: 120 ; Train RMSE = 0.9070 ; Test RMSE = 0.9391\n",
      "Iteration: 130 ; Train RMSE = 0.9028 ; Test RMSE = 0.9375\n",
      "Iteration: 140 ; Train RMSE = 0.8968 ; Test RMSE = 0.9352\n",
      "Iteration: 150 ; Train RMSE = 0.8887 ; Test RMSE = 0.9321\n",
      "Iteration: 160 ; Train RMSE = 0.8783 ; Test RMSE = 0.9282\n",
      "Iteration: 170 ; Train RMSE = 0.8661 ; Test RMSE = 0.9241\n",
      "Iteration: 180 ; Train RMSE = 0.8523 ; Test RMSE = 0.9202\n",
      "Iteration: 190 ; Train RMSE = 0.8371 ; Test RMSE = 0.9166\n",
      "Iteration: 200 ; Train RMSE = 0.8203 ; Test RMSE = 0.9135\n",
      "Iteration: 210 ; Train RMSE = 0.8018 ; Test RMSE = 0.9108\n",
      "Iteration: 220 ; Train RMSE = 0.7818 ; Test RMSE = 0.9086\n",
      "Iteration: 230 ; Train RMSE = 0.7603 ; Test RMSE = 0.9069\n",
      "Iteration: 240 ; Train RMSE = 0.7377 ; Test RMSE = 0.9058\n",
      "Iteration: 250 ; Train RMSE = 0.7141 ; Test RMSE = 0.9052\n"
     ]
    }
   ],
   "source": [
    "# 4_2.py\n",
    "\n",
    "##### CF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "rating_matrix = ratings_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "\n",
    "# train set 사용자들의 Cosine similarities 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "# train 데이터의 user의 rating 평균과 영화의 평점편차 계산 \n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T\n",
    "\n",
    "def CF_knn_bias(user_id, movie_id, neighbor_size=0):\n",
    "    if movie_id in rating_bias:\n",
    "        sim_scores = user_similarity[user_id]\n",
    "        movie_ratings = rating_bias[movie_id]\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "        if neighbor_size == 0:\n",
    "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "##### MF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0                    # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set                         # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        prediction = self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "        return prediction\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n",
    "\n",
    "# MF클래스 생성 및 학습\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=250, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9048049331445301"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Hybrid 추천 알고리즘\n",
    "\n",
    "def recommender0(recomm_list, mf):\n",
    "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "def recommender1(recomm_list, neighbor_size=0):\n",
    "    recommendations = np.array([CF_knn_bias(user, movie, neighbor_size) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])\n",
    "predictions0 = recommender0(recomm_list, mf)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions0)\n",
    "predictions1 = recommender1(recomm_list, 37)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions1)\n",
    "\n",
    "weight = [0.8, 0.2]\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### MF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0                    # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set                         # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        prediction = self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "        return prediction\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n",
    "\n",
    "\n",
    "\n",
    "##### DL 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
    "\n",
    "# Variable 초기화 \n",
    "K = 200                             # Latent factor 수 \n",
    "mu = ratings_train.rating.mean()    # 전체 평균 \n",
    "M = ratings.user_id.max() + 1       # Number of users\n",
    "N = ratings.movie_id.max() + 1      # Number of movies\n",
    "\n",
    "# Defining RMSE measure\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "##### (2)\n",
    "\n",
    "# Keras model\n",
    "user = Input(shape=(1, ))                                               # User input\n",
    "item = Input(shape=(1, ))                                               # Item input\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)        # (M, 1, K)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)        # (N, 1, K)\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)          # User bias term (M, 1, )\n",
    "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)          # Item bias term (N, 1, )\n",
    "\n",
    "# Concatenate layers\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "P_embedding = Flatten()(P_embedding)                                    # (K, )\n",
    "Q_embedding = Flatten()(Q_embedding)                                    # (K, )\n",
    "user_bias = Flatten()(user_bias)                                        # (1, )\n",
    "item_bias = Flatten()(item_bias)                                        # (1, )\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])     # (2K + 2, )\n",
    "\n",
    "# Neural network\n",
    "R = Dense(2048)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(256)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(1)(R)\n",
    "\n",
    "model = Model(inputs=[user, item], outputs=R)\n",
    "model.compile(\n",
    "  loss=RMSE,\n",
    "  optimizer=SGD(),\n",
    "  #optimizer=Adamax(),\n",
    "  metrics=[RMSE]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MF클래스 생성 및 학습\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=250, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75000 samples, validate on 25000 samples\n",
      "Epoch 1/65\n",
      "75000/75000 [==============================] - 4s 56us/sample - loss: 5.3978 - RMSE: 1.1245 - val_loss: 5.2716 - val_RMSE: 1.1242\n",
      "Epoch 2/65\n",
      "75000/75000 [==============================] - 4s 53us/sample - loss: 5.1522 - RMSE: 1.1231 - val_loss: 5.0333 - val_RMSE: 1.1224\n",
      "Epoch 3/65\n",
      "75000/75000 [==============================] - 4s 52us/sample - loss: 4.9207 - RMSE: 1.1214 - val_loss: 4.8086 - val_RMSE: 1.1212\n",
      "Epoch 4/65\n",
      "75000/75000 [==============================] - 4s 53us/sample - loss: 4.7022 - RMSE: 1.1200 - val_loss: 4.5969 - val_RMSE: 1.1196\n",
      "Epoch 5/65\n",
      "75000/75000 [==============================] - 4s 54us/sample - loss: 4.4963 - RMSE: 1.1185 - val_loss: 4.3972 - val_RMSE: 1.1185\n",
      "Epoch 6/65\n",
      "75000/75000 [==============================] - 4s 53us/sample - loss: 4.3021 - RMSE: 1.1172 - val_loss: 4.2084 - val_RMSE: 1.1168\n",
      "Epoch 7/65\n",
      "75000/75000 [==============================] - 4s 53us/sample - loss: 4.1187 - RMSE: 1.1155 - val_loss: 4.0307 - val_RMSE: 1.1152\n",
      "Epoch 8/65\n",
      "75000/75000 [==============================] - 4s 54us/sample - loss: 3.9457 - RMSE: 1.1134 - val_loss: 3.8625 - val_RMSE: 1.1132\n",
      "Epoch 9/65\n",
      "75000/75000 [==============================] - 4s 54us/sample - loss: 3.7823 - RMSE: 1.1115 - val_loss: 3.7040 - val_RMSE: 1.1114\n",
      "Epoch 10/65\n",
      "75000/75000 [==============================] - 4s 55us/sample - loss: 3.6279 - RMSE: 1.1091 - val_loss: 3.5542 - val_RMSE: 1.1092\n",
      "Epoch 11/65\n",
      "75000/75000 [==============================] - 4s 54us/sample - loss: 3.4820 - RMSE: 1.1066 - val_loss: 3.4122 - val_RMSE: 1.1064\n",
      "Epoch 12/65\n",
      "75000/75000 [==============================] - 4s 54us/sample - loss: 3.3441 - RMSE: 1.1039 - val_loss: 3.2782 - val_RMSE: 1.1037\n",
      "Epoch 13/65\n",
      "75000/75000 [==============================] - 4s 54us/sample - loss: 3.2134 - RMSE: 1.1006 - val_loss: 3.1514 - val_RMSE: 1.1003\n",
      "Epoch 14/65\n",
      "75000/75000 [==============================] - 4s 55us/sample - loss: 3.0897 - RMSE: 1.0970 - val_loss: 3.0308 - val_RMSE: 1.0960\n",
      "Epoch 15/65\n",
      "75000/75000 [==============================] - 4s 55us/sample - loss: 2.9723 - RMSE: 1.0924 - val_loss: 2.9170 - val_RMSE: 1.0919\n",
      "Epoch 16/65\n",
      "75000/75000 [==============================] - 5s 73us/sample - loss: 2.8606 - RMSE: 1.0871 - val_loss: 2.8082 - val_RMSE: 1.0864\n",
      "Epoch 17/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 2.7545 - RMSE: 1.0813 - val_loss: 2.7051 - val_RMSE: 1.0807\n",
      "Epoch 18/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 2.6535 - RMSE: 1.0747 - val_loss: 2.6067 - val_RMSE: 1.0736\n",
      "Epoch 19/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 2.5570 - RMSE: 1.0671 - val_loss: 2.5130 - val_RMSE: 1.0662\n",
      "Epoch 20/65\n",
      "75000/75000 [==============================] - 6s 80us/sample - loss: 2.4649 - RMSE: 1.0589 - val_loss: 2.4235 - val_RMSE: 1.0578\n",
      "Epoch 21/65\n",
      "75000/75000 [==============================] - 6s 81us/sample - loss: 2.3769 - RMSE: 1.0492 - val_loss: 2.3382 - val_RMSE: 1.0488\n",
      "Epoch 22/65\n",
      "75000/75000 [==============================] - 6s 80us/sample - loss: 2.2931 - RMSE: 1.0397 - val_loss: 2.2573 - val_RMSE: 1.0401\n",
      "Epoch 23/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 2.2134 - RMSE: 1.0298 - val_loss: 2.1799 - val_RMSE: 1.0302\n",
      "Epoch 24/65\n",
      "75000/75000 [==============================] - 5s 66us/sample - loss: 2.1375 - RMSE: 1.0199 - val_loss: 2.1072 - val_RMSE: 1.0213\n",
      "Epoch 25/65\n",
      "75000/75000 [==============================] - 5s 61us/sample - loss: 2.0657 - RMSE: 1.0097 - val_loss: 2.0388 - val_RMSE: 1.0130\n",
      "Epoch 26/65\n",
      "75000/75000 [==============================] - 5s 64us/sample - loss: 1.9981 - RMSE: 1.0007 - val_loss: 1.9735 - val_RMSE: 1.0046\n",
      "Epoch 27/65\n",
      "75000/75000 [==============================] - 6s 79us/sample - loss: 1.9343 - RMSE: 0.9923 - val_loss: 1.9130 - val_RMSE: 0.9977\n",
      "Epoch 28/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.8744 - RMSE: 0.9844 - val_loss: 1.8567 - val_RMSE: 0.9919\n",
      "Epoch 29/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 1.8183 - RMSE: 0.9773 - val_loss: 1.8017 - val_RMSE: 0.9848\n",
      "Epoch 30/65\n",
      "75000/75000 [==============================] - 6s 79us/sample - loss: 1.7655 - RMSE: 0.9711 - val_loss: 1.7518 - val_RMSE: 0.9798\n",
      "Epoch 31/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.7161 - RMSE: 0.9657 - val_loss: 1.7055 - val_RMSE: 0.9762\n",
      "Epoch 32/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 1.6697 - RMSE: 0.9606 - val_loss: 1.6604 - val_RMSE: 0.9715\n",
      "Epoch 33/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.6263 - RMSE: 0.9564 - val_loss: 1.6190 - val_RMSE: 0.9681\n",
      "Epoch 34/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 1.5855 - RMSE: 0.9522 - val_loss: 1.5800 - val_RMSE: 0.9651\n",
      "Epoch 35/65\n",
      "75000/75000 [==============================] - 6s 79us/sample - loss: 1.5470 - RMSE: 0.9486 - val_loss: 1.5430 - val_RMSE: 0.9616\n",
      "Epoch 36/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.5108 - RMSE: 0.9456 - val_loss: 1.5083 - val_RMSE: 0.9591\n",
      "Epoch 37/65\n",
      "75000/75000 [==============================] - 6s 79us/sample - loss: 1.4768 - RMSE: 0.9425 - val_loss: 1.4767 - val_RMSE: 0.9576\n",
      "Epoch 38/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.4451 - RMSE: 0.9402 - val_loss: 1.4461 - val_RMSE: 0.9554\n",
      "Epoch 39/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.4151 - RMSE: 0.9381 - val_loss: 1.4188 - val_RMSE: 0.9552\n",
      "Epoch 40/65\n",
      "75000/75000 [==============================] - 6s 79us/sample - loss: 1.3869 - RMSE: 0.9358 - val_loss: 1.3900 - val_RMSE: 0.9519\n",
      "Epoch 41/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 1.3605 - RMSE: 0.9342 - val_loss: 1.3649 - val_RMSE: 0.9508\n",
      "Epoch 42/65\n",
      "75000/75000 [==============================] - 6s 75us/sample - loss: 1.3353 - RMSE: 0.9324 - val_loss: 1.3413 - val_RMSE: 0.9495\n",
      "Epoch 43/65\n",
      "75000/75000 [==============================] - 6s 75us/sample - loss: 1.3121 - RMSE: 0.9309 - val_loss: 1.3185 - val_RMSE: 0.9480\n",
      "Epoch 44/65\n",
      "75000/75000 [==============================] - 6s 73us/sample - loss: 1.2898 - RMSE: 0.9294 - val_loss: 1.2972 - val_RMSE: 0.9468\n",
      "Epoch 45/65\n",
      "75000/75000 [==============================] - 5s 72us/sample - loss: 1.2691 - RMSE: 0.9283 - val_loss: 1.2775 - val_RMSE: 0.9459\n",
      "Epoch 46/65\n",
      "75000/75000 [==============================] - 6s 74us/sample - loss: 1.2496 - RMSE: 0.9272 - val_loss: 1.2606 - val_RMSE: 0.9472\n",
      "Epoch 47/65\n",
      "75000/75000 [==============================] - 6s 75us/sample - loss: 1.2313 - RMSE: 0.9263 - val_loss: 1.2412 - val_RMSE: 0.9448\n",
      "Epoch 48/65\n",
      "75000/75000 [==============================] - 6s 76us/sample - loss: 1.2139 - RMSE: 0.9256 - val_loss: 1.2245 - val_RMSE: 0.9441\n",
      "Epoch 49/65\n",
      "75000/75000 [==============================] - 6s 74us/sample - loss: 1.1976 - RMSE: 0.9247 - val_loss: 1.2088 - val_RMSE: 0.9432\n",
      "Epoch 50/65\n",
      "75000/75000 [==============================] - 6s 86us/sample - loss: 1.1824 - RMSE: 0.9240 - val_loss: 1.1943 - val_RMSE: 0.9431\n",
      "Epoch 51/65\n",
      "75000/75000 [==============================] - 7s 99us/sample - loss: 1.1678 - RMSE: 0.9235 - val_loss: 1.1813 - val_RMSE: 0.9435\n",
      "Epoch 52/65\n",
      "75000/75000 [==============================] - 6s 82us/sample - loss: 1.1543 - RMSE: 0.9231 - val_loss: 1.1673 - val_RMSE: 0.9422\n",
      "Epoch 53/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.1414 - RMSE: 0.9224 - val_loss: 1.1554 - val_RMSE: 0.9420\n",
      "Epoch 54/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 1.1293 - RMSE: 0.9219 - val_loss: 1.1456 - val_RMSE: 0.9438\n",
      "Epoch 55/65\n",
      "75000/75000 [==============================] - 6s 78us/sample - loss: 1.1180 - RMSE: 0.9215 - val_loss: 1.1342 - val_RMSE: 0.9433\n",
      "Epoch 56/65\n",
      "75000/75000 [==============================] - 6s 75us/sample - loss: 1.1073 - RMSE: 0.9213 - val_loss: 1.1275 - val_RMSE: 0.9464\n",
      "Epoch 57/65\n",
      "75000/75000 [==============================] - 6s 76us/sample - loss: 1.0971 - RMSE: 0.9208 - val_loss: 1.1140 - val_RMSE: 0.9425\n",
      "Epoch 58/65\n",
      "75000/75000 [==============================] - 6s 74us/sample - loss: 1.0877 - RMSE: 0.9210 - val_loss: 1.1045 - val_RMSE: 0.9420\n",
      "Epoch 59/65\n",
      "75000/75000 [==============================] - 5s 73us/sample - loss: 1.0790 - RMSE: 0.9208 - val_loss: 1.0953 - val_RMSE: 0.9413\n",
      "Epoch 60/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.0702 - RMSE: 0.9202 - val_loss: 1.0882 - val_RMSE: 0.9422\n",
      "Epoch 61/65\n",
      "75000/75000 [==============================] - 6s 76us/sample - loss: 1.0623 - RMSE: 0.9201 - val_loss: 1.0797 - val_RMSE: 0.9414\n",
      "Epoch 62/65\n",
      "75000/75000 [==============================] - 6s 80us/sample - loss: 1.0548 - RMSE: 0.9200 - val_loss: 1.0722 - val_RMSE: 0.9409\n",
      "Epoch 63/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.0474 - RMSE: 0.9194 - val_loss: 1.0653 - val_RMSE: 0.9408\n",
      "Epoch 64/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.0411 - RMSE: 0.9196 - val_loss: 1.0588 - val_RMSE: 0.9404\n",
      "Epoch 65/65\n",
      "75000/75000 [==============================] - 6s 77us/sample - loss: 1.0346 - RMSE: 0.9195 - val_loss: 1.0543 - val_RMSE: 0.9422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model fitting\n",
    "result = model.fit(\n",
    "  x=[ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "  y=ratings_train.rating.values - mu,\n",
    "  epochs=65,\n",
    "  batch_size=512,\n",
    "  validation_data=(\n",
    "    [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "    ratings_test.rating.values - mu\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92124077181604"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Hybrid 추천 알고리즘\n",
    "\n",
    "def recommender0(recomm_list, mf):\n",
    "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "def recommender1(recomm_list, model):\n",
    "    user_ids = recomm_list[:,0]\n",
    "    movie_ids = recomm_list[:,1]\n",
    "    recommendations = model.predict([user_ids, movie_ids]) + mu\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])\n",
    "predictions0 = recommender0(recomm_list, mf)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions0)\n",
    "\n",
    "predictions1 = recommender1(recomm_list, model)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions1)\n",
    "\n",
    "weight = [0.8, 0.2]\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80f13800544f689b6ae429e769f7d8a329da88a1fda391b7e028aa1280d902de"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('kooc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
